{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d16e5513",
   "metadata": {},
   "source": [
    "# 手写self-attention四重境界\n",
    "\n",
    "### step1:了解公式\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathrm{Attention}(Q, K, V) = \\mathrm{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V. \\tag{1}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "### step2:开始写代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dae9432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2, 4])\n"
     ]
    }
   ],
   "source": [
    "### 第一重境界： 简化版本\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SelfAttentionv1(nn.Module):\n",
    "    def __init__(self, hidden_dim:int  =728):\n",
    "        # 注意初始化\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # Q K V\n",
    "        self.Q_proj = nn.Linear(hidden_dim,hidden_dim)\n",
    "        self.K_proj = nn.Linear(hidden_dim,hidden_dim)\n",
    "        self.V_proj = nn.Linear(hidden_dim,hidden_dim)\n",
    "    \n",
    "    def forward(self,X):\n",
    "        # X shape: [batch_size,seq_len,hidden_dim]\n",
    "\n",
    "        # Q K V [batch_size,seq_len,hidden_dim]\n",
    "        Q = self.Q_proj(X)\n",
    "        K = self.K_proj(X)\n",
    "        V = self.V_proj(X)\n",
    "        \n",
    "        # 注意力分数 \n",
    "        # attention_scores shape: [batch_size,seq_len,seq_len]\n",
    "        attention_scores = torch.matmul(Q,K.transpose(-2,-1)) / math.sqrt(self.hidden_dim)\n",
    "        \n",
    "        # 注意力权重\n",
    "        attention_weights = torch.softmax(attention_scores,dim=-1)\n",
    "\n",
    "        #输出 \n",
    "        # output shape: [batch_size,seq_len,hidden_dim]\n",
    "        output = torch.matmul(attention_weights,V)\n",
    "        return output\n",
    "\n",
    "X = torch.randn(3,2,4)\n",
    "net = SelfAttentionv1(hidden_dim=4)\n",
    "res = net(X)\n",
    "print(res.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb463f6",
   "metadata": {},
   "source": [
    "### 第二重： 效率优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d36555",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttentionv2(nn.Module):\n",
    "    def __init__(self,dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.dim = dim\n",
    "\n",
    "        self.proj = nn.Linear(dim,dim * 3)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        \"\"\"\n",
    "        x: [batch, seq_len, dim]\n",
    "        qkv: [batch, seq_len, dim * 3]\n",
    "        \"\"\"\n",
    "        qkv = self.proj(x)\n",
    "        Q,K,V = torch.split(qkv,self.dim,dim=-1)\n",
    "\n",
    "        output = torch.softmax(Q @ K.transpose(-2,-1)/math.sqrt(self.dim),dim=-1)@V\n",
    "        print(output)\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64facfa3",
   "metadata": {},
   "source": [
    "### 第3重: 加入一些细节"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60db3a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_weight shape: torch.Size([3, 4, 4])\n",
      "attention_weight : tensor([[[0.3425, 0.3293, 0.3282, 0.0000],\n",
      "         [0.3375, 0.3199, 0.3426, 0.0000],\n",
      "         [0.3619, 0.3724, 0.2658, 0.0000],\n",
      "         [0.3705, 0.3969, 0.2326, 0.0000]],\n",
      "\n",
      "        [[0.3423, 0.6577, 0.0000, 0.0000],\n",
      "         [0.3595, 0.6405, 0.0000, 0.0000],\n",
      "         [0.4004, 0.5996, 0.0000, 0.0000],\n",
      "         [0.4761, 0.5239, 0.0000, 0.0000]],\n",
      "\n",
      "        [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [1.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2458, 0.7761],\n",
       "         [0.2472, 0.7549],\n",
       "         [0.2281, 0.7387],\n",
       "         [0.2187, 0.7188]],\n",
       "\n",
       "        [[0.5555, 1.4392],\n",
       "         [0.5634, 1.4581],\n",
       "         [0.5824, 1.5031],\n",
       "         [0.6175, 1.5865]],\n",
       "\n",
       "        [[0.1588, 0.5139],\n",
       "         [0.5770, 1.5795],\n",
       "         [0.5770, 1.5795],\n",
       "         [0.5770, 1.5795]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. dropout 位置\n",
    "# 2. attention_mask 部分\n",
    "# 3. output 矩阵映射(可选)\n",
    "\n",
    "class SelfAttentionv3(nn.Module):\n",
    "    def __init__(self, dim, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.dim = dim \n",
    "        self.proj = nn.Linear(dim, dim * 3)\n",
    "\n",
    "        self.attention_dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "        # 可选的 output 矩阵映射\n",
    "        self.output_proj = nn.Linear(dim, dim)\n",
    "\n",
    "    def forward(self,x,attention_mask=None):\n",
    "        # x shape [batch_size,seq_len,dim]\n",
    "        qkv = self.proj(x)\n",
    "\n",
    "        Q,K,V = torch.split(qkv,self.dim,dim=-1)\n",
    "\n",
    "        attention_weight = Q @ K.transpose(-1,-2) / math.sqrt(self.dim)\n",
    "        if attention_mask is not None:\n",
    "           attention_weight = attention_weight.masked_fill(attention_mask == 0, float(\"-1e20\"))\n",
    "\n",
    "        attention_weight = torch.softmax(attention_weight,dim = -1)\n",
    "        print(\"attention_weight shape:\",attention_weight.shape)\n",
    "        print(\"attention_weight :\",attention_weight)\n",
    "        # 最后对attention_weight进行dropout\n",
    "        attention_weight = self.attention_dropout(attention_weight)\n",
    "        # 增加了output_proj映射。\n",
    "        output = self.output_proj(torch.matmul(attention_weight,V))\n",
    "\n",
    "        return output\n",
    "\n",
    "# shape [batch_size,seq_len,dim]\n",
    "x = torch.randn(3,4,2)\n",
    "\n",
    "# mask矩阵应该和 attention_weight 形状相同 [batch_size,seq_len,seq_len]\n",
    "mask = torch.tensor(\n",
    "    [\n",
    "        [1,1,1,0],\n",
    "        [1,1,0,0],\n",
    "        [1,0,0,0]\n",
    "    ]\n",
    ")\n",
    "# print(\"mask shape:\",mask.shape)\n",
    "# mask.unsqueeze(1)是把mask从[batch_size,seq_len]变成[batch_size,1,seq_len]\n",
    "# 然后重复seq_len=4次，变成[batch_size,seq_len,seq_len]\n",
    "mask = mask.unsqueeze(1).repeat(1,4,1)\n",
    "# print(\"repeat mask shape:\",mask.shape)\n",
    "# print(\"repeat mask :\",mask)\n",
    "# mask shape: torch.Size([3, 4])\n",
    "# repeat mask shape: torch.Size([3, 4, 4])\n",
    "\n",
    "\n",
    "net =SelfAttentionv3(2)\n",
    "net(x,mask)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99959071",
   "metadata": {},
   "source": [
    "### 第4重: 面试写法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88ea0d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.5791, 0.0000, 0.4209],\n",
      "         [0.4932, 0.0000, 0.5068],\n",
      "         [0.5426, 0.0000, 0.4574]],\n",
      "\n",
      "        [[1.0000, 0.0000, 0.0000],\n",
      "         [1.0000, 0.0000, 0.0000],\n",
      "         [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 1.0000],\n",
      "         [0.0000, 0.0000, 1.0000],\n",
      "         [0.0000, 0.0000, 1.0000]]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[[-0.1486,  0.1214, -0.6503, -0.2755],\n",
      "         [-0.0382,  0.0863, -0.6434, -0.2326],\n",
      "         [-0.3743,  0.1591, -0.3713, -0.2634]],\n",
      "\n",
      "        [[ 0.8472, -0.2117, -0.3991,  0.0823],\n",
      "         [ 0.8472, -0.2117, -0.3991,  0.0823],\n",
      "         [ 0.8472, -0.2117, -0.3991,  0.0823]],\n",
      "\n",
      "        [[-0.0645,  0.2409, -0.2858, -0.4543],\n",
      "         [-0.0645,  0.2409, -0.2858, -0.4543],\n",
      "         [-0.0645,  0.2409, -0.2858, -0.4543]]], grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class SelfAttentionInterview(nn.Module):\n",
    "    def __init__(self,dim:int ,dropout_rate: float = 0.1) -> None:\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "        self.query = nn.Linear(dim,dim)\n",
    "        self.key = nn.Linear(dim,dim)\n",
    "        self.value = nn.Linear(dim,dim)\n",
    "\n",
    "        self.attention_dropout = nn.Dropout(dropout_rate)\n",
    "    \n",
    "    def forward(self, x, attention_mask=None):\n",
    "        # x [batch_size,seq_len,dim]\n",
    "        Q = self.query(x)\n",
    "        K = self.key(x)\n",
    "        V = self.value(x)\n",
    "\n",
    "        # [bacth_size,seq_len,seq_len]\n",
    "        attention_weight = Q @ K.transpose(-2,-1) / math.sqrt(self.dim)\n",
    "        if attention_mask is not None:\n",
    "            attention_weight = attention_weight.masked_fill(\n",
    "                attention_mask == 0,\n",
    "                float('-1e20')\n",
    "            )\n",
    "        \n",
    "        attention_weight = torch.softmax(attention_weight,dim=-1)\n",
    "        print(attention_weight)\n",
    "        attention_weight = self.attention_dropout(attention_weight)\n",
    "        # [batch_size,seq_len,dim]\n",
    "        output = attention_weight @ V\n",
    "        return output\n",
    "\n",
    "x = torch.randn(3,3,4)\n",
    "\n",
    "mask = torch.tensor(\n",
    "    [\n",
    "        [1,0,1],\n",
    "        [1,0,0],\n",
    "        [0,0,1]\n",
    "    ]\n",
    ")\n",
    "\n",
    "mask = mask.unsqueeze(1).repeat(1,3,1)\n",
    "net = SelfAttentionInterview(4)\n",
    "output = net(x,mask)\n",
    "print(output)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
