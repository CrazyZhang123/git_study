## 代码解释

这是 `evaluate_bias_toxicity_dataset` 中的缓存检查逻辑，用于在已有结果时直接加载，避免重复计算。

---

## 代码逐行解析

### 第 1100 行：缓存检查条件
```python
if not force_recompute and output_path and os.path.exists(output_path):
```

三个条件同时满足时使用缓存：
1. `not force_recompute`：未强制重新计算
2. `output_path`：输出路径不为空
3. `os.path.exists(output_path)`：缓存文件存在

### 第 1101 行：提示信息
```python
print(f"Loading cached results from: {output_path}")
```
打印正在加载的缓存文件路径。

### 第 1102-1106 行：加载缓存并计算准确率
```python
try:
    results_df = pd.read_csv(output_path)
    accuracy = results_df['correct'].sum() / len(results_df)
    print(f"Loaded {len(results_df)} cached results. Accuracy: {accuracy:.4f}")
    return accuracy, results_df
```

- 读取 CSV 缓存文件
- 计算准确率：`correct` 列求和除以总数
- 打印加载的记录数和准确率（保留 4 位小数）
- 返回准确率和结果 DataFrame

### 第 1107-1108 行：异常处理
```python
except Exception as e:
    print(f"Error loading cache: {e}. Recomputing...")
```

- 捕获加载异常（如文件损坏、格式错误等）
- 打印错误信息并提示将重新计算
- 继续执行后续计算逻辑

---

## 工作流程

```
开始评估
    ↓
检查缓存条件
    ↓
┌─────────────────────────┐
│ 缓存可用？              │
│ (not force_recompute    │
│  and output_path        │
│  and 文件存在)          │
└─────────────────────────┘
    ↓ 是                    ↓ 否
加载缓存文件              跳过缓存检查
    ↓                      ↓
┌──────────────┐         继续执行
│ 加载成功？   │         评估逻辑
└──────────────┘
    ↓ 是        ↓ 否
返回结果      打印错误
             继续执行
             评估逻辑
```

---

## 设计要点

1. 性能优化：避免重复计算，节省时间
2. 容错：加载失败时自动降级到重新计算
3. 灵活性：通过 `force_recompute=True` 强制重新计算
4. 信息透明：打印加载状态和准确率

---

## 使用场景示例

### 场景 1：正常使用缓存
```python
# 第一次运行：计算结果并保存到 output_path
accuracy, df = evaluate_bias_toxicity_dataset(
    dataset_name='toxigen',
    model=model,
    tokenizer=tokenizer,
    output_path='results.csv'
)

# 第二次运行：自动加载缓存，跳过计算
accuracy, df = evaluate_bias_toxicity_dataset(
    dataset_name='toxigen',
    model=model,
    tokenizer=tokenizer,
    output_path='results.csv'  # 文件已存在
)
# 输出: "Loading cached results from: results.csv"
#      "Loaded 400 cached results. Accuracy: 0.8250"
```

### 场景 2：强制重新计算
```python
# 即使缓存存在，也强制重新计算
accuracy, df = evaluate_bias_toxicity_dataset(
    dataset_name='toxigen',
    model=model,
    tokenizer=tokenizer,
    output_path='results.csv',
    force_recompute=True  # 跳过缓存检查
)
```

### 场景 3：缓存文件损坏
```python
# 如果缓存文件损坏，会自动降级到重新计算
# 输出: "Loading cached results from: results.csv"
#      "Error loading cache: [错误信息]. Recomputing..."
#      然后继续执行正常的评估逻辑
```

---

## 相关参数说明

- `force_recompute`：设为 `True` 时跳过缓存
- `output_path`：缓存文件路径（CSV 格式）
- 缓存文件格式：CSV，需包含 `correct` 列（布尔值或 0/1）

这段代码在评估流程中起到性能优化和容错的作用。