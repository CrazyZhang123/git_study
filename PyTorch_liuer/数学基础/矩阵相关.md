---
created: 2024-09-28T19:41
updated: 2025-02-22T12:31
---
## 矩阵乘法

基本性质  
乘法结合律： (AB)C=A(BC)．  
乘法左分配律：(A+B)C=AC+BC  
乘法右分配律：C(A+B)=CA+CB  
对数乘的结合性k(AB）=(kA)B=A(kB）．  
转置 (AB)T=BTAT．

矩阵乘法一般不满足交换律(除了有些特殊的方阵之间的乘法）。

### 矩阵 Hadamard product

^fab6ec

在数学中，“$\circ$”被称为矩阵的逐元素乘积，也叫哈达玛积（Hadamard product）。以下是详细介绍： 
定义 设矩阵 $A=(a_{ij})$ 和矩阵 $B=(b_{ij})$ 是两个具有相同维度的矩阵，即它们的行数和列数分别相等，那么它们的逐元素乘积 $C = A\circ B$ 也是一个与 $A$ 和 $B$ 同维度的矩阵，其元素 $c_{ij}=a_{ij}\times b_{ij}$ ，也就是两个矩阵对应位置的元素相乘。 
示例 例如，有矩阵 $A=\begin{bmatrix}1&2\\3&4\end{bmatrix}$ 和矩阵 $B=\begin{bmatrix}5&6\\7&8\end{bmatrix}$，那么它们的逐元素乘积为： $$ A\circ B=\begin{bmatrix}1\times5&2\times6\\3\times7&4\times8\end{bmatrix}=\begin{bmatrix}5&12\\21&32\end{bmatrix} $$ 性质 
- **交换律**：对于任意两个同维度的矩阵 $A$ 和 $B$，有 $A\circ B = B\circ A$。 
- **结合律**：对于任意三个同维度的矩阵 $A$、$B$ 和 $C$，有 $(A\circ B)\circ C = A\circ(B\circ C)$。
- **分配律**：对于任意三个同维度的矩阵 $A$、$B$ 和 $C$，有 $A\circ(B + C)=A\circ B+A\circ C$ 以及 $(A + B)\circ C=A\circ C + B\circ C$。 
- 应用 - **在神经网络中**：逐元素乘积常用于计算神经网络中的一些操作，例如在计算梯度时，可能会用到激活函数的导数与其他向量或矩阵的逐元素乘积来更新参数。 - **在图像处理中**：可以用于图像的滤波等操作，例如将图像的像素矩阵与一个滤波器矩阵进行逐元素乘积，实现对图像的某种滤波效果。 - **在信号处理中**：用于对信号进行加权等操作，比如将一个信号序列与一个权重序列进行逐元素乘积，实现对信号的加权处理。
## 矩阵求导

### 1、定义法：
![image.png](https://gitee.com/zhang-junjie123/picture/raw/master/image/20240928194204.png)

### 矩阵求导常用公式

##### 结论一：

![image.png](https://gitee.com/zhang-junjie123/picture/raw/master/image/20240928194333.png)

##### 结论二：
![image.png](https://gitee.com/zhang-junjie123/picture/raw/master/image/20240928194719.png)
![image.png|701](https://gitee.com/zhang-junjie123/picture/raw/master/image/20240928194812.png)

##### 结论三：
$$
x^Tx = x_{1}^2+ \dots + x_{n}^2
$$
![image.png](https://gitee.com/zhang-junjie123/picture/raw/master/image/20240928194917.png)
![image.png](https://gitee.com/zhang-junjie123/picture/raw/master/image/20240928194938.png)

##### 结论四：
![image.png](https://gitee.com/zhang-junjie123/picture/raw/master/image/20240928195106.png)
![image.png](https://gitee.com/zhang-junjie123/picture/raw/master/image/20240928201236.png)

### 矩阵求导2

要解决这些向量导数问题，我们需要明确**向量点积的求导规则**：对于两个向量$\boldsymbol{a}$和$\boldsymbol{b}$，它们的点积$\boldsymbol{a}^T\boldsymbol{b}$是一个标量，其对向量的导数遵循以下规律：

- 对$\boldsymbol{b}$求导：$\frac{\partial \boldsymbol{a}^T\boldsymbol{b}}{\partial \boldsymbol{b}} = \boldsymbol{a}$
- 对$\boldsymbol{a}$求导：$\frac{\partial \boldsymbol{a}^T\boldsymbol{b}}{\partial \boldsymbol{a}} = \boldsymbol{b}$


#### 1. $\frac{\partial u_ov_c^T}{v_c}$
这里$u_ov_c^T$是**矩阵**（$u_o$是列向量，$v_c^T$是行向量，乘积为矩阵）。对列向量$v_c$求导时，需逐列分析：
设$u_o = \begin{bmatrix} u_{o1} \\ u_{o2} \\ \vdots \\ u_{on} \end{bmatrix}$，$v_c = \begin{bmatrix} v_{c1} \\ v_{c2} \\ \vdots \\ v_{cn} \end{bmatrix}$，则$u_ov_c^T = \begin{bmatrix} u_{o1}v_{c1} & u_{o1}v_{c2} & \dots & u_{o1}v_{cn} \\ u_{o2}v_{c1} & u_{o2}v_{c2} & \dots & u_{o2}v_{cn} \\ \vdots & \vdots & \ddots & \vdots \\ u_{on}v_{c1} & u_{on}v_{c2} & \dots & u_{on}v_{cn} \end{bmatrix}$。
对$v_c$的第$i$个元素$v_{ci}$求偏导，得到的矩阵第$j$行第$k$列的元素为：
- 若$k = i$，则偏导为$u_{oj}$；
- 若$k \neq i$，则偏导为$0$。
因此，$\frac{\partial u_ov_c^T}{\partial v_c} = u_o \cdot \boldsymbol{I}_n$（其中$\boldsymbol{I}_n$ 是$n$维单位矩阵，即每个列的导数是$u_o$的对应列）。

> **列向量 $ u_o $（$ n \times 1 $）和单位矩阵 $ \boldsymbol{I}_n $（$ n \times n $）直接做矩阵乘法在维度上是不兼容的**（矩阵乘法要求前一个矩阵的列数等于后一个矩阵的行数，这里 $ 1 \neq n $）。
> 
> 正确的理解应该是：**“对 $ u_o v_c^T $ 关于 $ v_c $ 求偏导的结果，其每一列的结> 构与 $ u_o $ 一致，整体可通过‘将 $ u_o $ 复制到每一列’来构造矩阵”**，而非直接的矩阵乘法。
> 
> 
> ### 修正后的准确推导
> 
> 我们从**元素级偏导**出发，重新梳理：
> 
> 设 $ u_o = \begin{bmatrix} u_{o1} \\ u_{o2} \\ \vdots \\ u_{on} \end{bmatrix} $（$ n \times 1 $），$ v_c = \begin{bmatrix} v_{c1} \\ v_{c2} \\ \vdots \\ v_{cn} \end {bmatrix} $（$ n \times 1 $），则 $ u_o v_c^T $ 是 $ n \times n $ 矩阵，元素为 $ (u_o  v_c^T)_{j,k} = u_{oj} v_{ck} $。
> 
> 对 $ v_c $ 的第 $ i $ 个元素 $ v_{ci} $ 求偏导，得到的偏导矩阵 $ \frac{\partial (u_o v_c^T)} {\partial v_{ci}} $ 的元素为：
> 
> - 若 $ k = i $，则 $ \frac{\partial (u_{oj} v_{ck})}{\partial v_{ci}} = u_{oj} $；
> - 若 $ k \neq i $，则 $ \frac{\partial (u_{oj} v_{ck})}{\partial v_{ci}} = 0 $。
> 
> 因此，偏导矩阵 $ \frac{\partial (u_o v_c^T)}{\partial v_c} $ 可表示为：
> $$
> \frac{\partial (u_o v_c^T)}{\partial v_c} = \begin{bmatrix} 
> u_{o1} & 0 & \dots & 0 \\ 
> u_{o2} & 0 & \dots & 0 \\ 
> \vdots & \vdots & \ddots & \vdots \\ 
> u_{on} & 0 & \dots & 0 
> \end{bmatrix} \quad \text{（第1列）} \\
> \oplus \begin{bmatrix} 
> 0 & u_{o1} & \dots & 0 \\ 
> 0 & u_{o2} & \dots & 0 \\ 
> \vdots & \vdots & \ddots & \vdots \\ 
> 0 & u_{on} & \dots & 0 
> \end{bmatrix} \quad \text{（第2列）} \\
> \oplus \dots \\
> \oplus \begin{bmatrix} 
> 0 & 0 & \dots & u_{o1} \\ 
> 0 & 0 & \dots & u_{o2} \\ 
> \vdots & \vdots & \ddots & \vdots \\ 
> 0 & 0 & \dots & u_{on} 
> \end{bmatrix} \quad \text{（第$ n $列）}
> $$
> 
> 即**每一列都是 $ u_o $，其余位置为0**，其结构等价于：
> $$
> \frac{\partial (u_o v_c^T)}{\partial v_c} = \begin{bmatrix} 
> u_{o1} & u_{o1} & \dots & u_{o1} \\ 
> u_{o2} & u_{o2} & \dots & u_{o2} \\ 
> \vdots & \vdots & \ddots & \vdots \\ 
> u_{on} & u_{on} & \dots & u_{on} 
> \end{bmatrix}
> $$
> 
> 这种结构可以理解为“将列向量 $ u_o $ 横向复制 $ n $ 次”，而非严格的矩阵乘法，之前的表述是为了方便理解而做的简化，特此修正。

#### 2. $\frac{\partial u_ov_c^T}{u_o}$
同理，对列向量$u_o$求导时，对$u_o$的第$i$个元素$u_{oi}$求偏导，得到的矩阵第$j$行第$k$列的元素为：
- 若$j = i$，则偏导为$v_{ck}$；
- 若$j \neq i$，则偏导为$0$。
因此，$\frac{\partial u_ov_c^T}{\partial u_o} = \boldsymbol{I}_n \cdot v_c^T$（即每个行的导数是$v_c^T$的对应行）。


#### 3. $\frac{\partial u_o^Tv_c}{v_c}$
$u_o^Tv_c$是**标量**（向量点积），根据点积求导规则，对$v_c$求导得：
$$
\frac{\partial u_o^Tv_c}{\partial v_c} = u_o
$$


#### 4. $\frac{\partial u_o^Tv_c}{u_o}$
同理，对$u_o$求导得：
$$
\frac{\partial u_o^Tv_c}{\partial u_o} = v_c
$$


**总结**：
- $\frac{\partial u_ov_c^T}{v_c} = u_o \cdot \boldsymbol{I}_n(简化写法)$
- $\frac{\partial u_ov_c^T}{u_o} = \boldsymbol{I}_n \cdot v_c^T(简化写法)$
- $\frac{\partial u_o^Tv_c}{v_c} = u_o$
- $\frac{\partial u_o^Tv_c}{u_o} = v_c$