{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16b7c83a",
   "metadata": {},
   "source": [
    "# 1、RNNCell方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2fa805",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "input_size = 4\n",
    "hidden_size = 4\n",
    "batch_size = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ddd47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2char = ['e','h','l','o']\n",
    "\n",
    "x_data = [1,0,2,2,3]\n",
    "y_data = [3,1,2,3,2]\n",
    "\n",
    "one_hot_lookup = [[1,0,0,0],\n",
    "                  [0,1,0,0],\n",
    "                  [0,0,1,0],\n",
    "                  [0,0,0,1]]\n",
    "# one hot 编码\n",
    "x_one_hot = [one_hot_lookup[x] for x in x_data]\n",
    "# inputs: (seq_len,batch_size,input_size) (5,1,4)\n",
    "inputs = torch.Tensor(x_one_hot).view(-1,batch_size,input_size)\n",
    "# 此时 print(labels[0].shape) 为空，但我们需要他有一个维度。\n",
    "# labels = torch.LongTensor(y_data).view(-1)\n",
    "\n",
    "labels = torch.LongTensor(y_data).view(-1,1)\n",
    "\n",
    "# print(labels[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "152bef6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,batch_size):\n",
    "        super(Model,self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_size = batch_size\n",
    "        self.rnncell = torch.nn.RNNCell(self.input_size,self.hidden_size)\n",
    "\n",
    "    def forward(self,input,hidden):\n",
    "        hidden = self.rnncell(input,hidden)\n",
    "        return hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(self.batch_size,self.hidden_size)\n",
    "    \n",
    "net = Model(input_size,hidden_size,batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccd5a7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(),lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd1ca47",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'optimizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m15\u001b[39m):\n\u001b[0;32m      2\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 3\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m      4\u001b[0m     hidden \u001b[38;5;241m=\u001b[39m net\u001b[38;5;241m.\u001b[39minit_hidden()\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted string:\u001b[39m\u001b[38;5;124m'\u001b[39m,end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'optimizer' is not defined"
     ]
    }
   ],
   "source": [
    "for epoch in range(15):\n",
    "    loss = 0\n",
    "    optimizer.zero_grad()\n",
    "    hidden = net.init_hidden()\n",
    "    print('Predicted string:',end=' ')\n",
    "    flag = 0\n",
    "    # 模型进行一次完整的前向传播\n",
    "    for input,label in zip(inputs,labels):\n",
    "        # 前向传播\n",
    "        hidden = net(input,hidden)\n",
    "        if flag == 0:\n",
    "            print(f'input:{input},label:{label},hidden:{hidden}')\n",
    "            flag = 1\n",
    "        # 计算损失\n",
    "        loss += criterion(hidden,label)\n",
    "        # 得到h_t的对应字符\n",
    "        _,idx = hidden.max(dim=1)\n",
    "        print(idx2char[idx.item()],end='')\n",
    "    # 反向传播\n",
    "    loss.backward()\n",
    "    # 更新参数\n",
    "    optimizer.step()\n",
    "    print(', Epoch [%d/15] loss=%.4f' % (epoch+1,loss.item()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd6802c",
   "metadata": {},
   "source": [
    "# 2、RNN方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80efbd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "input_size = 4\n",
    "hidden_size = 4\n",
    "num_layers = 1\n",
    "batch_size = 1\n",
    "seq_len = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08bd63f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([[1., 1., 1., 1.]]),\n",
       "indices=tensor([[1, 0, 2, 4]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2char = ['e','h','l','o']\n",
    "\n",
    "x_data = [1,0,2,2,3]\n",
    "y_data = [3,1,2,3,2]\n",
    "\n",
    "one_hot_lookup = [[1,0,0,0],\n",
    "                  [0,1,0,0],\n",
    "                  [0,0,1,0],\n",
    "                  [0,0,0,1]]\n",
    "x_one_hot = [one_hot_lookup[x] for x in x_data]\n",
    "\n",
    "inputs = torch.Tensor(x_one_hot).view(seq_len,batch_size,input_size)\n",
    "# shape: (seq_len, batch_size, input_size)\n",
    "\n",
    "# torch.LongTensor 是 PyTorch 中的一个数据类型，用于表示包含整数（整型数据）的张量（tensor）。\n",
    "# 它是一种特定的张量类型，其中的元素都为整数类型，并且使用 64 位整数进行存储。\n",
    "labels = torch.LongTensor(y_data)\n",
    "# 推荐使用torch.tensor()\n",
    "labels = torch.tensor(y_data,dtype=torch.long)\n",
    "# shape: (seq_len * batch_size, 1)\n",
    "\n",
    "# print(labels[0].shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3701984b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_Model(torch.nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,batch_size,num_layers):\n",
    "        super(RNN_Model,self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_size = batch_size\n",
    "        self.rnn = torch.nn.RNN(self.input_size,self.hidden_size,num_layers=self.num_layers)\n",
    "\n",
    "\n",
    "    def forward(self,input):\n",
    "        # input shape: (seq_len, batch_size, input_size)\n",
    "        # hidden0 shape: (num_layers, batch_size, hidden_size)\n",
    "        hidden0 = torch.zeros(self.num_layers,self.batch_size,self.hidden_size)\n",
    "        # _是RNN的隐藏状态hidden，我们不需要它\n",
    "        out,_ = self.rnn(input,hidden0)\n",
    "        # out shape: (seq_len *batch_size, hidden_size)\n",
    "        return out.view(-1,self.hidden_size)\n",
    "    \n",
    "net = RNN_Model(input_size,hidden_size,batch_size,num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b681398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out.shape: torch.Size([5, 1, 4])\n",
      "out.shape: torch.Size([5, 1, 4])\n",
      "Predicted:  oehll, Epoch [1/15] loss=1.3548\n",
      "out.shape: torch.Size([5, 1, 4])\n",
      "out.shape: torch.Size([5, 1, 4])\n",
      "Predicted:  ollll, Epoch [2/15] loss=1.1208\n",
      "out.shape: torch.Size([5, 1, 4])\n",
      "out.shape: torch.Size([5, 1, 4])\n",
      "Predicted:  ollol, Epoch [3/15] loss=1.0043\n",
      "out.shape: torch.Size([5, 1, 4])\n",
      "out.shape: torch.Size([5, 1, 4])\n",
      "Predicted:  ooooo, Epoch [4/15] loss=0.9150\n",
      "out.shape: torch.Size([5, 1, 4])\n",
      "out.shape: torch.Size([5, 1, 4])\n",
      "Predicted:  ohooo, Epoch [5/15] loss=0.8360\n",
      "out.shape: torch.Size([5, 1, 4])\n",
      "out.shape: torch.Size([5, 1, 4])\n",
      "Predicted:  ohooo, Epoch [6/15] loss=0.7734\n",
      "out.shape: torch.Size([5, 1, 4])\n",
      "out.shape: torch.Size([5, 1, 4])\n",
      "Predicted:  ohool, Epoch [7/15] loss=0.7200\n",
      "out.shape: torch.Size([5, 1, 4])\n",
      "out.shape: torch.Size([5, 1, 4])\n",
      "Predicted:  ohool, Epoch [8/15] loss=0.6727\n",
      "out.shape: torch.Size([5, 1, 4])\n",
      "out.shape: torch.Size([5, 1, 4])\n",
      "Predicted:  ohool, Epoch [9/15] loss=0.6270\n",
      "out.shape: torch.Size([5, 1, 4])\n",
      "out.shape: torch.Size([5, 1, 4])\n",
      "Predicted:  ohool, Epoch [10/15] loss=0.5891\n",
      "out.shape: torch.Size([5, 1, 4])\n",
      "out.shape: torch.Size([5, 1, 4])\n",
      "Predicted:  ohool, Epoch [11/15] loss=0.5644\n",
      "out.shape: torch.Size([5, 1, 4])\n",
      "out.shape: torch.Size([5, 1, 4])\n",
      "Predicted:  ohool, Epoch [12/15] loss=0.5460\n",
      "out.shape: torch.Size([5, 1, 4])\n",
      "out.shape: torch.Size([5, 1, 4])\n",
      "Predicted:  ohlol, Epoch [13/15] loss=0.5281\n",
      "out.shape: torch.Size([5, 1, 4])\n",
      "out.shape: torch.Size([5, 1, 4])\n",
      "Predicted:  ohlol, Epoch [14/15] loss=0.5118\n",
      "out.shape: torch.Size([5, 1, 4])\n",
      "out.shape: torch.Size([5, 1, 4])\n",
      "Predicted:  ohlol, Epoch [15/15] loss=0.4991\n"
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(),lr=0.1)\n",
    "\n",
    "for epoch in range(15):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = net(inputs)\n",
    "    # inputs shape: (seq_len, batch_size, input_size)\n",
    "    # outputs shape: (seq_len * batch_size, hidden_size)\n",
    "    # labels shape: (seq_len * batch_size, 1)\n",
    "    loss = criterion(outputs,labels)\n",
    "    # 反向传播\n",
    "    loss.backward()\n",
    "    # 更新参数\n",
    "    optimizer.step()\n",
    "\n",
    "    # 得到h_t的预测字母结果对应的索引\n",
    "    # 第一个参数是dim=1的所有最大值，第二个参数是维度的索引\n",
    "    _,idx = outputs.max(dim=1)\n",
    "    # 将索引转化为numpy数组\n",
    "    idx = idx.data.numpy()\n",
    "    # 迭代idx数组，将每个索引对应的字母打印出来\n",
    "    print('Predicted: ',''.join([idx2char[x] for x in idx]),end='')\n",
    "    # .item() 将张量中的单个值转换为 Python 数字\n",
    "    # .data.numpy() 将张量转换为 NumPy 数组\n",
    "    print(', Epoch [%d/15] loss=%.4f' % (epoch+1,loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4877a248",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
