1.**机器学习可解释性中的激活修补 (Activation Patching)**： 这是指一种用于理解神经网络（尤其是大型语言模型）内部计算的机制可解释性技术。该方法通过将“损坏”输入上的模型激活（中间输出）替换为“干净”输入在特定层或位置的激活，然后观察其对模型输出的影响。这使得研究人员能够将特定的模型行为因果地归因于特定的内部组件或计算。例如，研究人员可以使用这种方法来评估大型语言模型生成自然语言解释的忠实性，或者定位模型中事实或定义性知识的存储位置。

2.**激活修补**是一种流行的研究技术，用于深入理解神经网络内部的“黑箱”工作机制，具体目标是定位模型中承载特定知识或执行特定任务的神经“电路”（circuits） 。

activate patching 通过将“损坏”输入上的模型激活（中间输出）替换为“干净”输入在特定层或位置的激活，然后观察其对模型输出的影响。其核心原理是**因果干预**，例如在模型运行过程中，研究人员选择一个“目标提示”（Target Prompt）来运行模型，但同时将模型内部特定位置的激活值替换为由另一个“源提示”（Source Prompt）产生的、先前缓存的激活值，然后观察这对最终模型输出的影响 。